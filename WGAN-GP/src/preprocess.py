# scripts/preprocess.py

import numpy as np
import pandas as pd
import os
from sklearn.preprocessing import StandardScaler, MinMaxScaler
import joblib  # ç”¨äºä¿å­˜ scaler

def main():
    # -------------------------------
    # 1. è·¯å¾„è®¾ç½®
    # -------------------------------
    input_csv = "/Users/zhanghongbo04/Downloads/video/zhb_test/foods/data/raw/corn_mp5_regression_data.csv"
    output_dir = "/Users/zhanghongbo04/Downloads/video/zhb_test/foods/data/processed"
    
    os.makedirs(output_dir, exist_ok=True)
    
    # -------------------------------
    # 2. è¯»å–æ•°æ®
    # -------------------------------
    print(f"Loading data from {input_csv}...")
    df = pd.read_csv(input_csv)
    
    # å…‰è°±åˆ—ï¼šWave_1 åˆ° Wave_700
    spectrum_cols = [col for col in df.columns if col.startswith("Wave_")]
    X = df[spectrum_cols].values  # (80, 700)
    
    # å±æ€§åˆ—
    target_names = ['Moisture', 'Starch', 'Oil', 'Protein']
    y = df[target_names].values   # (80, 4)
    
    print(f"Original spectra shape: {X.shape}")
    print(f"Original labels shape: {y.shape}")

    # -------------------------------
    # 3. æ•°æ®å½’ä¸€åŒ–
    # -------------------------------

    # --- å…‰è°±ï¼šä½¿ç”¨ StandardScalerï¼ˆZ-score: å‡å€¼0ï¼Œæ–¹å·®1ï¼‰---
    # é€‚åˆå…‰è°±ï¼Œä¿ç•™åˆ†å¸ƒç‰¹æ€§
    X_scaler = StandardScaler()
    X_scaled = X_scaler.fit_transform(X)  # (80, 700)

    # --- æ ‡ç­¾ï¼šä½¿ç”¨ MinMaxScalerï¼ˆç¼©æ”¾åˆ° [0,1] æˆ– [-1,1]ï¼‰---
    # æ›´é€‚åˆå±æ€§é¢„æµ‹ï¼Œç‰©ç†èŒƒå›´æ¸…æ™°
    y_scaler = MinMaxScaler(feature_range=(0, 1))  # ä¹Ÿå¯ä»¥ç”¨ (-1, 1)
    y_scaled = y_scaler.fit_transform(y)  # (80, 4)

    print("âœ… Data normalized:")
    print(f"  X: mean={X_scaled.mean():.3f}, std={X_scaled.std():.3f} (after StandardScaler)")
    print(f"  y: min={y_scaled.min():.3f}, max={y_scaled.max():.3f} (after MinMaxScaler)")

    # -------------------------------
    # 4. ä¿å­˜å½’ä¸€åŒ–åçš„æ•°æ®
    # -------------------------------
    np.save(os.path.join(output_dir, "train_spectra.npy"), X_scaled)
    np.save(os.path.join(output_dir, "train_labels.npy"), y_scaled)
    
    # -------------------------------
    # 5. ä¿å­˜ Scaler å¯¹è±¡ï¼ˆå…³é”®ï¼ç”¨äºåç»­é€†å˜æ¢ï¼‰
    # -------------------------------
    joblib.dump(X_scaler, os.path.join(output_dir, "X_scaler.pkl"))
    joblib.dump(y_scaler, os.path.join(output_dir, "y_scaler.pkl"))
    
    print(f"âœ… Saved normalized data and scalers to {output_dir}")

    # -------------------------------
    # 6. å¯é€‰ï¼šæ‰“å°åŸå§‹ vs å½’ä¸€åŒ–èŒƒå›´ï¼ˆç”¨äºæ£€æŸ¥ï¼‰
    # -------------------------------
    print("\nğŸ“Œ Scaler info (for reference):")
    print("Moisture range:", y[:, 0].min(), "â†’", y[:, 0].max())
    print("Starch range:", y[:, 1].min(), "â†’", y[:, 1].max())
    print("Oil range:", y[:, 2].min(), "â†’", y[:, 2].max())
    print("Protein range:", y[:, 3].min(), "â†’", y[:, 3].max())


if __name__ == "__main__":
    main()