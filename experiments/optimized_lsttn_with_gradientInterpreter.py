# experiments/optimized_lsttn_regression.py

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import joblib
import os
import time
import math
import matplotlib.pyplot as plt
import seaborn as sns
os.environ['CUDA_VISIBLE_DEVICES'] = '4'
# å¯¼å…¥å·¥å…·å‡½æ•°
from utils import load_data, evaluate_model, plot_predictions, save_results_to_csv
torch.backends.cudnn.enabled = False
print("cuDNN å·²ç¦ç”¨ï¼Œä½¿ç”¨æ›¿ä»£å®ç°")

class MultiScaleSpectralAttention(nn.Module):
    """å¤šå°ºåº¦å…‰è°±æ³¨æ„åŠ›æœºåˆ¶"""
    def __init__(self, input_dim, hidden_dim):
        super().__init__()
        self.scales = [3, 7, 15, 31]  # ä¸åŒå°ºåº¦çš„å·ç§¯æ ¸
        self.scale_convs = nn.ModuleList([
            nn.Conv1d(input_dim, hidden_dim // len(self.scales), 
                     kernel_size=scale, padding=scale//2)
            for scale in self.scales
        ])
        self.attention = nn.MultiheadAttention(hidden_dim, num_heads=8, batch_first=True)
        self.norm = nn.LayerNorm(hidden_dim)
        
        # ä¿å­˜æ³¨æ„åŠ›æƒé‡ç”¨äºå¯è§†åŒ–
        # self.attention_weights = None
        
    def forward(self, x):
        # x: (batch, seq_len, input_dim)
        x_conv = x.transpose(1, 2)  # (batch, input_dim, seq_len)
        
        # å¤šå°ºåº¦ç‰¹å¾æå–
        scale_features = []
        for conv in self.scale_convs:
            feat = conv(x_conv)  # (batch, hidden_dim//4, seq_len)
            scale_features.append(feat)
        
        # æ‹¼æ¥å¤šå°ºåº¦ç‰¹å¾
        multi_scale = torch.cat(scale_features, dim=1)  # (batch, hidden_dim, seq_len)
        multi_scale = multi_scale.transpose(1, 2)  # (batch, seq_len, hidden_dim)
        
        # è‡ªæ³¨æ„åŠ›
        attended, attention_weights = self.attention(multi_scale, multi_scale, multi_scale)
        # self.attention_weights = attention_weights  # ä¿å­˜æ³¨æ„åŠ›æƒé‡
        output = self.norm(attended + multi_scale)
        
        return output

class SpectralPositionalEncoding(nn.Module):
    """å…‰è°±ä¸“ç”¨ä½ç½®ç¼–ç """
    def __init__(self, d_model, max_len=200):  # æ”¹ä¸º200
        super().__init__()
        
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * 
                           (-math.log(10000.0) / d_model))
        
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        
        # æ·»åŠ å…‰è°±é¢‘ç‡ç›¸å…³çš„ç¼–ç 
        spectral_factor = torch.linspace(0, 1, max_len).unsqueeze(1)
        pe = pe * (1 + 0.1 * spectral_factor)
        
        self.register_buffer('pe', pe)
    
    def forward(self, x):
        seq_len = x.size(1)
        return x + self.pe[:seq_len].unsqueeze(0)

class AdaptivePatchEmbedding(nn.Module):
    """è‡ªé€‚åº”patchåµŒå…¥"""
    def __init__(self, input_dim, embed_dim, patch_sizes=[8, 12, 16]):
        super().__init__()
        self.patch_sizes = patch_sizes
        self.embed_dim = embed_dim
        
        # ç¡®ä¿èƒ½æ­£ç¡®åˆ†é…ç»´åº¦
        if embed_dim % len(patch_sizes) != 0:
            # å¦‚æœä¸èƒ½æ•´é™¤ï¼Œæ‰‹åŠ¨åˆ†é…
            base_dim = embed_dim // len(patch_sizes)
            remainder = embed_dim % len(patch_sizes)
            dims = [base_dim + (1 if i < remainder else 0) for i in range(len(patch_sizes))]
        else:
            dims = [embed_dim // len(patch_sizes)] * len(patch_sizes)
        
        # å¤šä¸ªä¸åŒå¤§å°çš„patchåµŒå…¥
        self.patch_embeds = nn.ModuleList([
            nn.Conv1d(1, dim, kernel_size=ps, stride=ps)
            for ps, dim in zip(patch_sizes, dims)
        ])
        
        # è‡ªé€‚åº”æƒé‡
        self.patch_weights = nn.Parameter(torch.ones(len(patch_sizes)))
        
    def forward(self, x):
        # x: (batch, 1, 700)
        patch_features = []
        
        for i, (patch_embed, patch_size) in enumerate(zip(self.patch_embeds, self.patch_sizes)):
            # ç¡®ä¿èƒ½è¢«patch_sizeæ•´é™¤
            seq_len = x.size(2)
            trimmed_len = (seq_len // patch_size) * patch_size
            x_trimmed = x[:, :, :trimmed_len]
            
            feat = patch_embed(x_trimmed)  # (batch, dim, num_patches)
            patch_features.append(feat)
        
        # åŠ æƒèåˆä¸åŒpatch sizeçš„ç‰¹å¾
        weights = F.softmax(self.patch_weights, dim=0)
        weighted_features = []
        min_patches = min([feat.size(2) for feat in patch_features])
        
        for i, feat in enumerate(patch_features):
            feat_trimmed = feat[:, :, :min_patches]
            weighted_features.append(feat_trimmed * weights[i])
        
        # æ‹¼æ¥ç‰¹å¾
        output = torch.cat(weighted_features, dim=1)  # (batch, embed_dim, num_patches)
        return output.transpose(1, 2)  # (batch, num_patches, embed_dim)

class EnhancedTransformerBlock(nn.Module):
    """å¢å¼ºçš„Transformerå—"""
    def __init__(self, d_model, nhead, dim_feedforward, dropout=0.1):
        super().__init__()
        
        # æ ‡å‡†æ³¨æ„åŠ›
        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=True)
        self.norm1 = nn.LayerNorm(d_model)
        self.norm2 = nn.LayerNorm(d_model)
        self.dropout = nn.Dropout(dropout)
        
        # å·ç§¯å‰é¦ˆç½‘ç»œï¼ˆæ›´é€‚åˆå…‰è°±æ•°æ®ï¼‰
        self.conv_ffn = nn.Sequential(
            nn.Conv1d(d_model, dim_feedforward, 1),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Conv1d(dim_feedforward, d_model, 1),
            nn.Dropout(dropout)
        )
        
        # ä¿å­˜æ³¨æ„åŠ›æƒé‡ç”¨äºå¯è§†åŒ–
        # self.attention_weights = None
        
    def forward(self, x):
        # è‡ªæ³¨æ„åŠ›
        attn_out, attention_weights = self.self_attn(x, x, x)
        # self.attention_weights = attention_weights  # ä¿å­˜æ³¨æ„åŠ›æƒé‡
        x = self.norm1(x + self.dropout(attn_out))
        
        # å·ç§¯å‰é¦ˆ
        x_conv = x.transpose(1, 2)  # (batch, d_model, seq_len)
        ffn_out = self.conv_ffn(x_conv)
        ffn_out = ffn_out.transpose(1, 2)  # (batch, seq_len, d_model)
        
        x = self.norm2(x + ffn_out)
        return x

class OptimizedSpectralLSTTN(nn.Module):
    """ä¼˜åŒ–ç‰ˆ LSTTN å…‰è°±å›å½’æ¨¡å‹"""
    def __init__(self, input_dim=700, output_dim=4, hidden_dim=128):
        super().__init__()
        
        self.hidden_dim = hidden_dim
        
        # 1. è‡ªé€‚åº”patchåµŒå…¥
        self.patch_embedding = AdaptivePatchEmbedding(
            input_dim, hidden_dim, patch_sizes=[8, 12, 16]
        )
        
        # 2. å…‰è°±ä¸“ç”¨ä½ç½®ç¼–ç 
        self.pos_encoding = SpectralPositionalEncoding(hidden_dim, max_len=512) 
        
        # 3. å¤šå°ºåº¦å…‰è°±æ³¨æ„åŠ›
        self.multi_scale_attn = MultiScaleSpectralAttention(hidden_dim, hidden_dim)
        
        # 4. å¢å¼ºTransformerç¼–ç å™¨
        self.transformer_layers = nn.ModuleList([
            EnhancedTransformerBlock(hidden_dim, nhead=8, dim_feedforward=hidden_dim*4)
            for _ in range(6)  # å¢åŠ å±‚æ•°
        ])
        
        # 5. å¤šè·¯å¾„ç‰¹å¾æå–å™¨
        # å…¨å±€è·¯å¾„ï¼šæ•´ä½“è¶‹åŠ¿
        self.global_extractor = nn.Sequential(
            nn.AdaptiveAvgPool1d(1),
            nn.Flatten(),
            nn.Linear(hidden_dim, 64),
            nn.ReLU(),
            nn.Dropout(0.2)
        )
        
        # å±€éƒ¨è·¯å¾„ï¼šå…³é”®åŒºåŸŸ
        self.local_extractor = nn.Sequential(
            nn.Conv1d(hidden_dim, 64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.AdaptiveMaxPool1d(1),
            nn.Flatten(),
            nn.Dropout(0.2)
        )
        
        # åºåˆ—è·¯å¾„ï¼šæ—¶åºä¿¡æ¯
        self.sequence_extractor = nn.LSTM(
            hidden_dim, 32, batch_first=True, bidirectional=True
        )
        
        # 6. è‡ªæ³¨æ„åŠ›èåˆ
        self.fusion_attention = nn.MultiheadAttention(
            embed_dim=64+64+64, num_heads=8, batch_first=True
        )
        
        # 7. ä»»åŠ¡ç‰¹å®šé¢„æµ‹å¤´
        task_dims = {'moisture': 32, 'starch': 32, 'oil': 48, 'protein': 48}  # æ ¹æ®éš¾åº¦è°ƒæ•´
        
        self.task_heads = nn.ModuleDict({
            task: nn.Sequential(
                nn.Linear(64+64+64, dim),
                nn.ReLU(),
                nn.Dropout(0.3),
                nn.Linear(dim, dim//2),
                nn.ReLU(),
                nn.Linear(dim//2, 1)
            ) for task, dim in task_dims.items()
        })
        
        # 8. æ®‹å·®è¿æ¥çš„æœ€ç»ˆé¢„æµ‹
        self.final_predictor = nn.Sequential(
            nn.Linear(64+64+64, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(128, output_dim)
        )
        
    def forward(self, x):
        batch_size = x.shape[0]
        
        # 1. æ·»åŠ é€šé“ç»´åº¦å¹¶è¿›è¡ŒpatchåµŒå…¥
        x = x.unsqueeze(1)  # (batch, 1, 700)
        x = self.patch_embedding(x)  # (batch, num_patches, hidden_dim)
        
        # 2. ä½ç½®ç¼–ç 
        x = self.pos_encoding(x)
        
        # 3. å¤šå°ºåº¦æ³¨æ„åŠ›
        x = self.multi_scale_attn(x)
        
        # 4. Transformerç¼–ç  (ä¿å­˜æ¯å±‚çš„æ³¨æ„åŠ›æƒé‡)
        attention_weights_list = []
        for layer in self.transformer_layers:
            x = layer(x)
            # if layer.attention_weights is not None:
            #     attention_weights_list.append(layer.attention_weights)
        
        # ä¿å­˜æ³¨æ„åŠ›æƒé‡ç”¨äºå¯è§†åŒ–
        # self.attention_weights_list = attention_weights_list
        
        # 5. å¤šè·¯å¾„ç‰¹å¾æå–
        x_transpose = x.transpose(1, 2)  # (batch, hidden_dim, seq_len)
        
        # å…¨å±€ç‰¹å¾
        global_feat = self.global_extractor(x_transpose)  # (batch, 64)
        
        # å±€éƒ¨ç‰¹å¾
        local_feat = self.local_extractor(x_transpose)  # (batch, 64)
        
        # åºåˆ—ç‰¹å¾
        seq_feat, _ = self.sequence_extractor(x)  # (batch, seq_len, 64)
        seq_feat = seq_feat.mean(dim=1)  # (batch, 64)
        
        # 6. ç‰¹å¾èåˆ
        combined_feat = torch.cat([global_feat, local_feat, seq_feat], dim=1)  # (batch, 192)
        
        # è‡ªæ³¨æ„åŠ›èåˆ
        fused_feat = combined_feat.unsqueeze(1)  # (batch, 1, 192)
        fused_feat, attention_weights_fusion = self.fusion_attention(fused_feat, fused_feat, fused_feat)
        # self.fusion_attention_weights = attention_weights_fusion  # ä¿å­˜èåˆæ³¨æ„åŠ›æƒé‡
        fused_feat = fused_feat.squeeze(1)  # (batch, 192)
        
        # 7. ä»»åŠ¡ç‰¹å®šé¢„æµ‹
        task_outputs = []
        task_names = ['moisture', 'starch', 'oil', 'protein']
        
        for task in task_names:
            task_out = self.task_heads[task](fused_feat)
            task_outputs.append(task_out)
        
        task_pred = torch.cat(task_outputs, dim=1)  # (batch, 4)
        
        # 8. æœ€ç»ˆé¢„æµ‹ï¼ˆæ®‹å·®è¿æ¥ï¼‰
        final_pred = self.final_predictor(fused_feat)
        
        # åŠ æƒèåˆä»»åŠ¡ç‰¹å®šå’Œé€šç”¨é¢„æµ‹
        alpha = 0.7  # å¯å­¦ä¹ å‚æ•°
        output = alpha * task_pred + (1 - alpha) * final_pred
        
        return output

class GradientInterpreter:
    """
    åŸºäºæ¢¯åº¦çš„æ¨¡å‹å¯è§£é‡Šæ€§åˆ†æå·¥å…·
    æä¾›è¾“å…¥ç‰¹å¾é‡è¦æ€§åˆ†æå’Œä¸­é—´å±‚é‡è¦æ€§åˆ†æ
    """
    def __init__(self, model, device='cpu'):
        self.model = model
        self.device = device
        self.model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    
    def compute_feature_importance(self, X, target_component=0):
        """
        è®¡ç®—è¾“å…¥ç‰¹å¾ï¼ˆæ³¢é•¿ï¼‰å¯¹ç‰¹å®šè¾“å‡ºæˆåˆ†çš„é‡è¦æ€§
        target_component: 0=æ°´åˆ†, 1=æ·€ç²‰, 2=æ²¹è„‚, 3=è›‹ç™½è´¨
        """
        if not isinstance(X, torch.Tensor):
            X = torch.FloatTensor(X).to(self.device)
        else:
            X = X.to(self.device)
        
        if len(X.shape) == 1:
            X = X.unsqueeze(0)
        
        # ä¸´æ—¶åˆ‡æ¢åˆ°è®­ç»ƒæ¨¡å¼ä»¥ç¡®ä¿æ¢¯åº¦è®¡ç®—
        original_mode = self.model.training
        self.model.train()
        
        try:
            # æ¸…é™¤ä¹‹å‰çš„æ¢¯åº¦
            self.model.zero_grad()
            
            # é‡æ–°åˆ›å»ºéœ€è¦æ¢¯åº¦çš„è¾“å…¥
            X_with_grad = X.clone().detach().requires_grad_(True)
            
            print("=== è°ƒè¯•ä¿¡æ¯ ===")
            print("Input requires_grad:", X_with_grad.requires_grad)
            
            # é€å±‚æ£€æŸ¥æ¢¯åº¦ä¼ æ’­
            with torch.set_grad_enabled(True):
                # 1. æ£€æŸ¥patch embedding
                x1 = X_with_grad.unsqueeze(1)
                print("After unsqueeze requires_grad:", x1.requires_grad)
                
                x2 = self.model.patch_embedding(x1)
                print("After patch_embedding requires_grad:", x2.requires_grad)
                
                # 2. æ£€æŸ¥ä½ç½®ç¼–ç 
                x3 = self.model.pos_encoding(x2)
                print("After pos_encoding requires_grad:", x3.requires_grad)
                
                # 3. æ£€æŸ¥å¤šå°ºåº¦æ³¨æ„åŠ›
                x4 = self.model.multi_scale_attn(x3)
                print("After multi_scale_attn requires_grad:", x4.requires_grad)
                
                # 4. æ£€æŸ¥transformerå±‚
                x5 = x4
                for i, layer in enumerate(self.model.transformer_layers):
                    x5 = layer(x5)
                    print(f"After transformer layer {i} requires_grad:", x5.requires_grad)
                    if not x5.requires_grad:
                        print(f"âŒ é—®é¢˜å‡ºç°åœ¨ç¬¬ {i} å±‚ Transformer")
                        break
                
                # 5. ç»§ç»­æ£€æŸ¥åç»­å±‚...
                output = self.model(X_with_grad)
                print("Final output requires_grad:", output.requires_grad)
                
                if not output.requires_grad:
                    print("âŒ æ¢¯åº¦åœ¨æ¨¡å‹ä¸­æŸå¤„ä¸­æ–­äº†")
                    return None, None
                
                # é€‰æ‹©ç‰¹å®šç›®æ ‡æˆåˆ†
                target_output = output[:, target_component]
                
                # è®¡ç®—æ¢¯åº¦
                gradients = torch.autograd.grad(
                    outputs=target_output,
                    inputs=X_with_grad,
                    grad_outputs=torch.ones_like(target_output),
                    create_graph=False,
                    retain_graph=False,
                    only_inputs=True
                )[0]
                
                importance = torch.abs(gradients)
                
                return importance.detach().cpu().numpy(), output.detach().cpu().numpy()
        
        except Exception as e:
            print(f"âŒ è®¡ç®—æ¢¯åº¦æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            return None, None
        
        finally:
            # æ¢å¤åŸæ¥çš„æ¨¡å¼
            self.model.train(original_mode)
    
    def compute_integrated_gradients(self, X, target_component=0, steps=50):
        """
        è®¡ç®—ç§¯åˆ†æ¢¯åº¦ï¼ˆIntegrated Gradientsï¼‰ï¼Œæ›´ç¨³å®šçš„ç‰¹å¾é‡è¦æ€§è¯„ä¼°
        """
        if not isinstance(X, torch.Tensor):
            X = torch.FloatTensor(X).to(self.device)
        
        if len(X.shape) == 1:
            X = X.unsqueeze(0)
        
        # åŸºçº¿è¾“å…¥ï¼ˆå¯ä»¥æ˜¯é›¶å‘é‡æˆ–éšæœºå™ªå£°ï¼‰
        baseline = torch.zeros_like(X)
        
        # ç”Ÿæˆä»åŸºçº¿åˆ°è¾“å…¥ä¹‹é—´çš„è·¯å¾„
        scaled_inputs = [baseline + (float(i) / steps) * (X - baseline) for i in range(0, steps + 1)]
        scaled_inputs = torch.stack(scaled_inputs)
        
        # è®¡ç®—æ¯ä¸ªè·¯å¾„ç‚¹çš„æ¢¯åº¦
        gradients = []
        for input_step in scaled_inputs:
            input_step.requires_grad_(True)
            output = self.model(input_step)
            target_output = output[:, target_component]
            
            self.model.zero_grad()
            target_output.backward(torch.ones_like(target_output))
            
            grad = input_step.grad.detach().cpu().numpy()
            gradients.append(grad)
            
        # è®¡ç®—ç§¯åˆ†æ¢¯åº¦è¿‘ä¼¼ï¼ˆé»æ›¼å’Œï¼‰
        gradients = np.array(gradients)
        avg_gradients = np.mean(gradients[:-1], axis=0)
        integrated_gradients = (X.detach().cpu().numpy() - baseline.detach().cpu().numpy()) * avg_gradients
        
        return integrated_gradients, output.detach().cpu().numpy()

def visualize_feature_importance(importance_scores, 
                                original_spectrum, 
                                sample_idx, 
                                epoch, 
                                target_name,
                                save_dir="experiments/results/feature_importance"):
    """
    å¯è§†åŒ–ç‰¹å¾é‡è¦æ€§å¹¶å°†ç»“æœä¿å­˜ä¸ºå›¾ç‰‡
    """
    os.makedirs(save_dir, exist_ok=True)
    
    # ç¡®ä¿é‡è¦æ€§åˆ†æ•°å’ŒåŸå§‹å…‰è°±é•¿åº¦ä¸€è‡´
    assert len(importance_scores) == len(original_spectrum), \
        f"é‡è¦æ€§åˆ†æ•°é•¿åº¦({len(importance_scores)})ä¸å…‰è°±é•¿åº¦({len(original_spectrum)})ä¸åŒ¹é…"
    
    wavelengths = np.arange(len(original_spectrum))
    
    # åˆ›å»ºå›¾è¡¨
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))
    
    # ç»˜åˆ¶åŸå§‹å…‰è°±
    ax1.plot(wavelengths, original_spectrum, 'b-', alpha=0.7, linewidth=1)
    ax1.set_title(f'Original NIR Spectrum - Sample {sample_idx}')
    ax1.set_xlabel('Wavelength Index')
    ax1.set_ylabel('Absorbance')
    ax1.grid(True, alpha=0.3)
    
    # ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§
    ax2.bar(wavelengths, importance_scores, alpha=0.6, color='red', width=1.0)
    ax2.set_title(f'Feature Importance for {target_name} Prediction - Epoch {epoch}')
    ax2.set_xlabel('Wavelength Index')
    ax2.set_ylabel('Importance Score (|dOutput / dInput|)')
    ax2.grid(True, alpha=0.3)
    
    # æ ‡è¯†æœ€é‡è¦çš„5ä¸ªæ³¢é•¿ç‚¹
    top5_indices = np.argsort(importance_scores)[-5:][::-1]
    for i, idx in enumerate(top5_indices):
        ax2.annotate(f'Top {i+1}', 
                    xy=(idx, importance_scores[idx]),
                    xytext=(5, 5), textcoords='offset points',
                    bbox=dict(boxstyle="round,pad=0.3", fc="yellow", alpha=0.5),
                    fontsize=8)
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    filename = f"{target_name}_importance_sample_{sample_idx}_epoch_{epoch}.png"
    save_path = os.path.join(save_dir, filename)
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    return save_path

def visualize_component_comparison(importance_scores_list, component_names, 
                                  sample_idx, epoch, 
                                  save_dir="experiments/results/component_comparison"):
    """
    å¯è§†åŒ–ä¸åŒæˆåˆ†çš„ç‰¹å¾é‡è¦æ€§å¯¹æ¯”
    """
    os.makedirs(save_dir, exist_ok=True)
    
    plt.figure(figsize=(14, 8))
    
    # ç»˜åˆ¶æ¯ä¸ªæˆåˆ†çš„é‡è¦æ€§æ›²çº¿
    for i, (scores, name) in enumerate(zip(importance_scores_list, component_names)):
        plt.plot(scores, alpha=0.7, label=name, linewidth=1.5)
    
    plt.title(f'Feature Importance Comparison Across Components - Sample {sample_idx} - Epoch {epoch}')
    plt.xlabel('Wavelength Index')
    plt.ylabel('Importance Score')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # ä¿å­˜å›¾ç‰‡
    filename = f"component_comparison_sample_{sample_idx}_epoch_{epoch}.png"
    save_path = os.path.join(save_dir, filename)
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    return save_path

def visualize_attention_weights(model, X_sample, sample_idx=0, save_dir="experiments/results/attention_maps", device='cpu'):
    """å¯è§†åŒ–æ³¨æ„åŠ›æƒé‡"""
    os.makedirs(save_dir, exist_ok=True)
    torch.backends.cudnn.enabled = False

    model.eval()
    model.to(device)
    
    with torch.no_grad():
        X_tensor = torch.FloatTensor(X_sample).unsqueeze(0).to(device)
        _ = model(X_tensor)
        
        # å¯è§†åŒ–å¤šå°ºåº¦æ³¨æ„åŠ›
        if hasattr(model.multi_scale_attn, 'attention_weights') and model.multi_scale_attn.attention_weights is not None:
            attn_weights = model.multi_scale_attn.attention_weights
            print(f"âœ… å¤šå°ºåº¦æ³¨æ„åŠ›æƒé‡å½¢çŠ¶: {attn_weights.shape}")
            print(f"æ³¨æ„åŠ›æƒé‡ç±»å‹: {type(attn_weights)}")
            
            # æ£€æŸ¥ä¸åŒçš„ç»´åº¦æƒ…å†µ
            if isinstance(attn_weights, torch.Tensor):
                if len(attn_weights.shape) == 4:  # (batch, heads, seq_len, seq_len)
                    attn_map = attn_weights[0, 0, :, :].cpu().numpy()
                elif len(attn_weights.shape) == 3:  # (heads, seq_len, seq_len)
                    attn_map = attn_weights[0, :, :].cpu().numpy()
                elif len(attn_weights.shape) == 2:  # (seq_len, seq_len)
                    attn_map = attn_weights.cpu().numpy()
                else:
                    print(f"æœªçŸ¥çš„æ³¨æ„åŠ›æƒé‡å½¢çŠ¶: {attn_weights.shape}")
                    return
                
                plt.figure(figsize=(10, 8))
                sns.heatmap(attn_map, cmap='viridis', cbar=True)
                plt.title(f'Multi-Scale Attention Weights - Sample {sample_idx}')
                plt.xlabel('Key Positions')
                plt.ylabel('Query Positions')
                plt.tight_layout()
                save_path = os.path.join(save_dir, f'multi_scale_attention_sample_{sample_idx}.png')
                plt.savefig(save_path, dpi=300, bbox_inches='tight')
                plt.close()
                print(f"âœ… ä¿å­˜å¤šå°ºåº¦æ³¨æ„åŠ›å›¾: {save_path}")
            else:
                print("æ³¨æ„åŠ›æƒé‡ä¸æ˜¯Tensorç±»å‹")
        
        # å¯è§†åŒ–Transformerå„å±‚æ³¨æ„åŠ›
        if hasattr(model, 'attention_weights_list') and model.attention_weights_list:
            for layer_idx, attn_weights in enumerate(model.attention_weights_list):
                print(f"Transformerå±‚ {layer_idx+1} æ³¨æ„åŠ›æƒé‡å½¢çŠ¶: {attn_weights.shape}")
                if isinstance(attn_weights, torch.Tensor):
                    if len(attn_weights.shape) == 4:  # (batch, heads, seq_len, seq_len)
                        attn_map = attn_weights[0, 0, :, :].cpu().numpy()
                    elif len(attn_weights.shape) == 3:  # (heads, seq_len, seq_len)
                        attn_map = attn_weights[0, :, :].cpu().numpy()
                    elif len(attn_weights.shape) == 2:  # (seq_len, seq_len)
                        attn_map = attn_weights.cpu().numpy()
                    else:
                        print(f"æœªçŸ¥çš„æ³¨æ„åŠ›æƒé‡å½¢çŠ¶: {attn_weights.shape}")
                        continue
                    
                    plt.figure(figsize=(10, 8))
                    sns.heatmap(attn_map, cmap='viridis', cbar=True)
                    plt.title(f'Transformer Layer {layer_idx+1} Attention Weights - Sample {sample_idx}')
                    plt.xlabel('Key Positions')
                    plt.ylabel('Query Positions')
                    plt.tight_layout()
                    save_path = os.path.join(save_dir, f'transformer_layer_{layer_idx+1}_attention_sample_{sample_idx}.png')
                    plt.savefig(save_path, dpi=300, bbox_inches='tight')
                    plt.close()
                    print(f"âœ… ä¿å­˜Transformerå±‚{layer_idx+1}æ³¨æ„åŠ›å›¾: {save_path}")
                else:
                    print("æ³¨æ„åŠ›æƒé‡ä¸æ˜¯Tensorç±»å‹")

def generate_interpretability_report(model, X_test, y_test, scaler_y, device='cpu'):
    """
    ç”Ÿæˆæœ€ç»ˆçš„å¯è§£é‡Šæ€§åˆ†ææŠ¥å‘Š
    """
    print("ğŸ“Š ç”Ÿæˆæœ€ç»ˆå¯è§£é‡Šæ€§åˆ†ææŠ¥å‘Š...")
    
    interpreter = GradientInterpreter(model, device)
    component_names = ['Moisture', 'Starch', 'Oil', 'Protein']
    
    # åˆ›å»ºæŠ¥å‘Šç›®å½•
    report_dir = "experiments/results/interpretability_report"
    os.makedirs(report_dir, exist_ok=True)
    
    # é€‰æ‹©å‡ ä¸ªæµ‹è¯•æ ·æœ¬è¿›è¡Œè¯¦ç»†åˆ†æ
    sample_indices = [0, 5, 10, 15, 20]
    
    # åˆ†ææ¯ä¸ªæ ·æœ¬
    for i, idx in enumerate(sample_indices):
        if idx < len(X_test):
            sample = X_test[idx]
            true_values = y_test[idx]
            
            plt.figure(figsize=(16, 12))
            
            # è·å–é¢„æµ‹å€¼
            with torch.no_grad():
                sample_tensor = torch.FloatTensor(sample).unsqueeze(0).to(device)
                prediction = model(sample_tensor).cpu().numpy()
                prediction = scaler_y.inverse_transform(prediction.reshape(1, -1)).squeeze()
            
            # è®¡ç®—æ¯ä¸ªæˆåˆ†çš„é‡è¦æ€§
            importance_maps = []
            for comp_idx, comp_name in enumerate(component_names):
                importance, _ = interpreter.compute_feature_importance(sample, comp_idx)
                importance_maps.append(importance.squeeze())
            
            # åˆ›å»ºç»¼åˆå¯è§†åŒ–
            for comp_idx, comp_name in enumerate(component_names):
                plt.subplot(2, 2, comp_idx + 1)
                
                # ç»˜åˆ¶åŸå§‹å…‰è°±å’Œé‡è¦æ€§å åŠ 
                wavelengths = np.arange(len(sample))
                ax1 = plt.gca()
                ax2 = ax1.twinx()
                
                # åŸå§‹å…‰è°±
                ax1.plot(wavelengths, sample, 'b-', alpha=0.7, label='Spectrum')
                ax1.set_xlabel('Wavelength Index')
                ax1.set_ylabel('Absorbance', color='b')
                ax1.tick_params(axis='y', labelcolor='b')
                
                # é‡è¦æ€§åˆ†æ•°
                ax2.fill_between(wavelengths, 0, importance_maps[comp_idx], 
                               alpha=0.3, color='r', label='Importance')
                ax2.set_ylabel('Importance Score', color='r')
                ax2.tick_params(axis='y', labelcolor='r')
                
                plt.title(f'{comp_name}\nTrue: {true_values[comp_idx]:.3f}, Pred: {prediction[comp_idx]:.3f}')
                
                # æ·»åŠ å›¾ä¾‹
                lines1, labels1 = ax1.get_legend_handles_labels()
                lines2, labels2 = ax2.get_legend_handles_labels()
                ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper right')
            
            plt.tight_layout()
            plt.suptitle(f'Feature Importance Analysis - Sample {idx}\n', fontsize=16)
            plt.subplots_adjust(top=0.93)
            
            # ä¿å­˜ç»¼åˆæŠ¥å‘Š
            report_path = os.path.join(report_dir, f'interpretability_report_sample_{idx}.png')
            plt.savefig(report_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"âœ… æ ·æœ¬ {idx} çš„å¯è§£é‡Šæ€§æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
    
    # ç”Ÿæˆå…¨å±€ç‰¹å¾é‡è¦æ€§æ€»ç»“
    plt.figure(figsize=(14, 10))
    
    # è®¡ç®—æ‰€æœ‰æµ‹è¯•æ ·æœ¬çš„å¹³å‡é‡è¦æ€§
    avg_importances = np.zeros((len(component_names), X_test.shape[1]))
    
    for comp_idx in range(len(component_names)):
        sample_importances = []
        for i in range(min(50, len(X_test))):  # ä½¿ç”¨å‰50ä¸ªæ ·æœ¬è®¡ç®—å¹³å‡
            importance, _ = interpreter.compute_feature_importance(X_test[i], comp_idx)
            sample_importances.append(importance.squeeze())
        
        avg_importances[comp_idx] = np.mean(sample_importances, axis=0)
    
    # ç»˜åˆ¶å…¨å±€é‡è¦æ€§
    for comp_idx, comp_name in enumerate(component_names):
        plt.subplot(2, 2, comp_idx + 1)
        plt.plot(avg_importances[comp_idx], 'r-', alpha=0.8)
        plt.title(f'Global Feature Importance - {comp_name}')
        plt.xlabel('Wavelength Index')
        plt.ylabel('Average Importance Score')
        plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    global_report_path = os.path.join(report_dir, 'global_feature_importance.png')
    plt.savefig(global_report_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"âœ… å…¨å±€ç‰¹å¾é‡è¦æ€§æŠ¥å‘Šå·²ä¿å­˜: {global_report_path}")
    print("ğŸ“‹ å¯è§£é‡Šæ€§åˆ†ææŠ¥å‘Šç”Ÿæˆå®Œæˆ!")

def train_optimized_lsttn_model(model, train_loader, val_loader, X_train_tensor, epochs=150, lr=0.0008, device='cpu'):
    """è®­ç»ƒä¼˜åŒ–ç‰ˆLSTTNæ¨¡å‹"""
    
    # å¤šä»»åŠ¡æŸå¤±å‡½æ•°
    def multi_task_loss(pred, target):
        # åŸºç¡€MSEæŸå¤±
        mse_loss = F.mse_loss(pred, target)
        
        # L1æ­£åˆ™åŒ–
        l1_loss = F.l1_loss(pred, target)
        
        # ä»»åŠ¡å¹³è¡¡æŸå¤±
        task_losses = []
        for i in range(target.size(1)):
            task_loss = F.mse_loss(pred[:, i], target[:, i])
            task_losses.append(task_loss)
        
        # åŠ¨æ€æƒé‡è°ƒæ•´
        task_weights = torch.tensor([1.2, 1.0, 1.5, 2.0]).to(device)  # æ ¹æ®ä»»åŠ¡éš¾åº¦è°ƒæ•´
        weighted_loss = sum(w * l for w, l in zip(task_weights, task_losses))
        
        return 0.7 * mse_loss + 0.2 * l1_loss + 0.1 * weighted_loss
    
    # ä¼˜åŒ–å™¨è®¾ç½®
    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = torch.optim.lr_scheduler.OneCycleLR(
        optimizer, max_lr=lr, epochs=epochs, 
        steps_per_epoch=len(train_loader),
        pct_start=0.3, anneal_strategy='cos'
    )
    
    model.to(device)
    best_loss = float('inf')
    patience = 20
    patience_counter = 0
    
    # åˆ›å»ºå¯è§£é‡Šæ€§åˆ†æå™¨
    interpreter = GradientInterpreter(model, device)
    
    # é€‰æ‹©å‡ ä¸ªä»£è¡¨æ€§æ ·æœ¬è¿›è¡Œåˆ†æ
    analysis_samples = []
    sample_indices = [0, 1, 2, 5, 10]  # é€‰æ‹©ä¸åŒçš„æ ·æœ¬è¿›è¡Œåˆ†æ
    for idx in sample_indices:
        if idx < len(X_train_tensor):
            analysis_samples.append(X_train_tensor[idx])
    
    component_names = ['Moisture', 'Starch', 'Oil', 'Protein']
    
    for epoch in range(epochs):
        # è®­ç»ƒå¾ªç¯
        model.train()
        train_loss = 0
        for X_batch, y_batch in train_loader:
            X_batch, y_batch = X_batch.to(device), y_batch.to(device)
            
            optimizer.zero_grad()
            outputs = model(X_batch)
            loss = multi_task_loss(outputs, y_batch)
            
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()
            scheduler.step()
            
            train_loss += loss.item()
        
        # éªŒè¯å¾ªç¯
        model.eval()
        val_loss = 0
        with torch.no_grad():
            for X_batch, y_batch in val_loader:
                X_batch, y_batch = X_batch.to(device), y_batch.to(device)
                outputs = model(X_batch)
                loss = multi_task_loss(outputs, y_batch)
                val_loss += loss.item()
        
        avg_val_loss = val_loss / len(val_loader)
        
        # æ¯20ä¸ªepochè¿›è¡Œä¸€æ¬¡å¯è§£é‡Šæ€§åˆ†æ
        if epoch % 20 == 0 or epoch == epochs - 1:
            print(f"Epoch {epoch}, Train Loss: {train_loss/len(train_loader):.6f}, Val Loss: {avg_val_loss:.6f}")
            
            # è¿›è¡Œå¯è§£é‡Šæ€§åˆ†æ
            model.eval()
            with torch.no_grad():
                # å¯¹æ¯ä¸ªåˆ†ææ ·æœ¬è¿›è¡Œåˆ†æ
                for sample_idx, sample in enumerate(analysis_samples):
                    if sample_idx < 3:  # åªåˆ†æå‰3ä¸ªæ ·æœ¬ä»¥å‡å°‘è®¡ç®—é‡
                        # åˆ†ææ¯ä¸ªæˆåˆ†çš„é‡è¦æ€§
                        sample_on_device = sample.to(device)

                        all_importances = []
                        
                        for comp_idx, comp_name in enumerate(component_names):
                            # è®¡ç®—ç‰¹å¾é‡è¦æ€§
                            importance, prediction = interpreter.compute_feature_importance(
                                sample_on_device, target_component=comp_idx
                            )
                            
                            # å¯è§†åŒ–å¹¶ä¿å­˜
                            save_path = visualize_feature_importance(
                                importance.squeeze(),
                                sample.cpu().numpy().squeeze(),
                                sample_idx,
                                epoch,
                                comp_name,
                                save_dir="experiments/results/feature_importance"
                            )
                            
                            all_importances.append(importance.squeeze())
                        
                        # å¯è§†åŒ–ä¸åŒæˆåˆ†çš„é‡è¦æ€§å¯¹æ¯”
                        comp_save_path = visualize_component_comparison(
                            all_importances,
                            component_names,
                            sample_idx,
                            epoch,
                            save_dir="experiments/results/component_comparison"
                        )
                        
                        print(f"âœ… å¯è§£é‡Šæ€§åˆ†æç»“æœå·²ä¿å­˜: {save_path}, {comp_save_path}")
        
        # æ—©åœæœºåˆ¶
        if avg_val_loss < best_loss:
            best_loss = avg_val_loss
            patience_counter = 0
            torch.save(model.state_dict(), "experiments/models/optimized_lsttn_best.pth")
        else:
            patience_counter += 1
            if patience_counter >= patience and epoch > 50:
                print(f"Early stopping at epoch {epoch}")
                break
    
    return model

def run_optimized_lsttn_experiment():
    """è¿è¡Œä¼˜åŒ–ç‰ˆLSTTNå›å½’å®éªŒ"""
    print("ğŸš€ å¼€å§‹ä¼˜åŒ–ç‰ˆ LSTTN å›å½’å®éªŒ...")
    
    # åŠ è½½æ•°æ®
    (X_train, X_test, y_train_scaled, y_test_scaled, 
     scaler_X, scaler_y, y_train_orig, y_test_orig) = load_data()
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ–¥ï¸ ä½¿ç”¨è®¾å¤‡: {device}")
    
    # æ•°æ®å¢å¼ºå‡½æ•° (å¯æ ¹æ®éœ€è¦å¯ç”¨)
    def augment_spectral_data(X, y, noise_level=0.005, shift_range=2):
        """è½»é‡çº§å…‰è°±æ•°æ®å¢å¼º"""
        augmented_X, augmented_y = [], []
        
        for i in range(len(X)):
            # åŸå§‹æ•°æ®
            augmented_X.append(X[i])
            augmented_y.append(y[i])
            
            # æ·»åŠ è½»å¾®å™ªå£°
            noise = np.random.normal(0, noise_level, X[i].shape)
            augmented_X.append(X[i] + noise)
            augmented_y.append(y[i])
            
            # è½»å¾®å…‰è°±åç§»
            shift = np.random.randint(-shift_range, shift_range+1)
            if shift != 0:
                shifted_x = np.roll(X[i], shift)
                augmented_X.append(shifted_x)
                augmented_y.append(y[i])
        
        return np.array(augmented_X), np.array(augmented_y)
    
    # åº”ç”¨è½»é‡çº§æ•°æ®å¢å¼º (å¯é€‰)
    # X_train_aug, y_train_scaled_aug = augment_spectral_data(X_train, y_train_scaled)
    # print(f"ğŸ“ˆ è½»é‡çº§æ•°æ®å¢å¼ºå: {X_train_aug.shape[0]} æ ·æœ¬")
    
    # ä¸ä½¿ç”¨æ•°æ®å¢å¼º
    X_train_aug, y_train_scaled_aug = X_train, y_train_scaled
    print(f"ğŸ“ˆ ä½¿ç”¨åŸå§‹æ•°æ®: {X_train_aug.shape[0]} æ ·æœ¬")
    
    # è½¬æ¢ä¸ºå¼ é‡
    X_train_tensor = torch.FloatTensor(X_train_aug)
    y_train_tensor = torch.FloatTensor(y_train_scaled_aug)
    X_test_tensor = torch.FloatTensor(X_test)
    y_test_tensor = torch.FloatTensor(y_test_scaled)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    from torch.utils.data import DataLoader, TensorDataset
    
    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=True)
    
    val_dataset = TensorDataset(X_test_tensor, y_test_tensor)
    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
    
    # åˆ›å»ºä¼˜åŒ–æ¨¡å‹
    model = OptimizedSpectralLSTTN(input_dim=700, output_dim=4, hidden_dim=128)
    total_params = sum(p.numel() for p in model.parameters())
    print(f"ğŸ§  æ¨¡å‹å‚æ•°é‡: {total_params:,}")
    
    # è®­ç»ƒæ¨¡å‹
    print("ğŸ§  è®­ç»ƒä¼˜åŒ–ç‰ˆ LSTTN æ¨¡å‹...")
    model = train_optimized_lsttn_model(
        model, train_loader, val_loader, X_train_tensor,
        epochs=250, lr=0.001, device=device
    )
    
    # åŠ è½½æœ€ä½³æ¨¡å‹
    model.load_state_dict(torch.load("experiments/models/optimized_lsttn_best.pth", map_location=device))
    
    # é¢„æµ‹
    print("ğŸ”® è¿›è¡Œé¢„æµ‹...")
    model.eval()
    with torch.no_grad():
        X_test_tensor = X_test_tensor.to(device)
        y_pred_scaled = model(X_test_tensor).cpu().numpy()
    
    y_pred_orig = scaler_y.inverse_transform(y_pred_scaled)
    
    # è¯„ä¼°
    metrics = evaluate_model(
        y_test_orig, y_pred_orig, 
        model_name="Optimized-LSTTN",
        scaler_y=None
    )
    
    # ç”»å›¾
    plot_predictions(
        y_test_orig, y_pred_orig,
        model_name="Optimized LSTTN",
        save_path="experiments/results/optimized_lsttn_predictions.png"
    )
    
    # æ³¨æ„åŠ›å¯è§†åŒ–
    print("ğŸ¨ ç”Ÿæˆæ³¨æ„åŠ›çƒ­åŠ›å›¾...")
    # é€‰æ‹©å‡ ä¸ªæµ‹è¯•æ ·æœ¬è¿›è¡Œå¯è§†åŒ–
    sample_indices = [0, 1, 2, 5, 10]  # é€‰æ‹©å‰å‡ ä¸ªæ ·æœ¬
    for idx in sample_indices:
        if idx < len(X_test):
            visualize_attention_weights(model, X_test[idx], idx, device=device)
    
    print("ğŸ“Š æ³¨æ„åŠ›çƒ­åŠ›å›¾å·²ä¿å­˜åˆ°: experiments/results/attention_maps/")
    
    # ç”Ÿæˆæœ€ç»ˆçš„å¯è§£é‡Šæ€§åˆ†ææŠ¥å‘Š
    generate_interpretability_report(
        model, 
        X_test, 
        y_test_orig,  # ä½¿ç”¨é€†å˜æ¢åçš„åŸå§‹å€¼
        scaler_y, 
        device=device
    )
    
    # ä¿å­˜ç»“æœ
    save_results_to_csv(metrics, "Optimized-LSTTN")
    
    # ä¿å­˜æ¨¡å‹
    model_dir = "experiments/models"
    os.makedirs(model_dir, exist_ok=True)
    
    torch.save(model.state_dict(), os.path.join(model_dir, "optimized_lsttn_model.pth"))
    joblib.dump(scaler_X, os.path.join(model_dir, "optimized_lsttn_scaler_X.pkl"))
    joblib.dump(scaler_y, os.path.join(model_dir, "optimized_lsttn_scaler_y.pkl"))
    
    print("âœ… ä¼˜åŒ–ç‰ˆ LSTTN å›å½’å®éªŒå®Œæˆ")
    print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜åˆ°: {model_dir}")
    
    return metrics

if __name__ == "__main__":
    run_optimized_lsttn_experiment()