
import numpy as np
import pandas as pd
from sklearn.cross_decomposition import PLSRegression
import joblib
import os

# å¯¼å…¥å·¥å…·å‡½æ•°
from utils import load_data, evaluate_model, plot_predictions, save_results_to_csv

def run_pls_experiment():
    """è¿è¡Œ PLS å®éªŒ"""
    print("ğŸš€ å¼€å§‹ PLS å®éªŒ...")
    
    # åŠ è½½æ•°æ®
    (X_train, X_test, y_train_scaled, y_test_scaled, 
     scaler_X, scaler_y, y_train_orig, y_test_orig) = load_data()
    
    # è®­ç»ƒ PLS æ¨¡å‹
    print("ğŸ§  è®­ç»ƒ PLS æ¨¡å‹...")
    pls = PLSRegression(n_components=10)
    pls.fit(X_train, y_train_scaled)
    
    # é¢„æµ‹
    print("ğŸ”® è¿›è¡Œé¢„æµ‹...")
    y_pred_scaled = pls.predict(X_test)
    y_pred_orig = scaler_y.inverse_transform(y_pred_scaled)
    
    # è¯„ä¼°
    metrics = evaluate_model(
        y_test_orig, y_pred_orig, 
        model_name="PLS",
        scaler_y=None  # å·²ç»è¿˜åŸäº†å•ä½
    )
    
    # ç”»å›¾
    plot_predictions(
        y_test_orig, y_pred_orig,
        model_name="PLS",
        save_path="experiments/results/pls_predictions.png"
    )
    
    # ä¿å­˜ç»“æœåˆ° CSV
    save_results_to_csv(metrics, "PLS")
    
    # ä¿å­˜æ¨¡å‹å’Œå½’ä¸€åŒ–å™¨
    model_dir = "experiments/models"
    os.makedirs(model_dir, exist_ok=True)
    
    joblib.dump(pls, os.path.join(model_dir, "pls_model.pkl"))
    joblib.dump(scaler_X, os.path.join(model_dir, "pls_scaler_X.pkl"))
    joblib.dump(scaler_y, os.path.join(model_dir, "pls_scaler_y.pkl"))
    
    print("âœ… PLS å®éªŒå®Œæˆ")
    print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜åˆ°: {model_dir}")
    
    return metrics

if __name__ == "__main__":
    run_pls_experiment()