# experiments/utils.py

import numpy as np
import pandas as pd
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import matplotlib.pyplot as plt
import os

def evaluate_model(y_true, y_pred, target_names=None, scaler_y=None, model_name="Model"):
    """
    è¯„ä¼°å›å½’æ¨¡å‹æ€§èƒ½
    
    Parameters:
    - y_true: çœŸå®å€¼ (n_samples, n_targets)
    - y_pred: é¢„æµ‹å€¼ (n_samples, n_targets)
    - target_names: ç›®æ ‡å˜é‡åç§°åˆ—è¡¨
    - scaler_y: yçš„å½’ä¸€åŒ–å™¨ï¼ˆç”¨äºè¿˜åŸå•ä½ï¼‰
    - model_name: æ¨¡å‹åç§°
    
    Returns:
    - metrics: åŒ…å«å„é¡¹æŒ‡æ ‡çš„å­—å…¸
    """
    if target_names is None:
        target_names = ['Moisture', 'Starch', 'Oil', 'Protein']
    
    # å¦‚æœæä¾›äº†å½’ä¸€åŒ–å™¨ï¼Œè¿˜åŸåˆ°åŸå§‹å•ä½
    if scaler_y is not None:
        y_true_orig = scaler_y.inverse_transform(y_true)
        y_pred_orig = scaler_y.inverse_transform(y_pred)
    else:
        y_true_orig = y_true
        y_pred_orig = y_pred
    
    metrics = {}
    print(f"ğŸ¯ {model_name} è¯„ä¼°ç»“æœ:")
    print("-" * 50)
    
    total_r2 = 0
    total_rmse = 0
    
    for i, name in enumerate(target_names):
        # è®¡ç®—æŒ‡æ ‡
        r2 = r2_score(y_true_orig[:, i], y_pred_orig[:, i])
        rmse = np.sqrt(mean_squared_error(y_true_orig[:, i], y_pred_orig[:, i]))
        mae = mean_absolute_error(y_true_orig[:, i], y_pred_orig[:, i])
        
        metrics[name] = {
            'R2': r2,
            'RMSE': rmse,
            'MAE': mae
        }
        
        total_r2 += r2
        total_rmse += rmse
        
        print(f"  {name:8s}: RÂ²={r2:6.4f}, RMSE={rmse:6.4f}, MAE={mae:6.4f}")
    
    avg_r2 = total_r2 / len(target_names)
    avg_rmse = total_rmse / len(target_names)
    metrics['Average'] = {
        'R2': avg_r2,
        'RMSE': avg_rmse
    }
    
    print("-" * 50)
    print(f"  {'Average':8s}: RÂ²={avg_r2:6.4f}, RMSE={avg_rmse:6.4f}")
    print()
    
    return metrics

def plot_predictions(y_true, y_pred, target_names=None, model_name="Model", save_path=None):
    """
    ç”»å‡ºé¢„æµ‹å€¼ vs çœŸå®å€¼çš„æ•£ç‚¹å›¾
    
    Parameters:
    - y_true: çœŸå®å€¼
    - y_pred: é¢„æµ‹å€¼
    - target_names: ç›®æ ‡å˜é‡åç§°
    - model_name: æ¨¡å‹åç§°
    - save_path: ä¿å­˜è·¯å¾„
    """
    if target_names is None:
        target_names = ['Moisture', 'Starch', 'Oil', 'Protein']
    
    plt.figure(figsize=(15, 12))
    
    for i, name in enumerate(target_names):
        plt.subplot(2, 2, i+1)
        
        y_t = y_true[:, i]
        y_p = y_pred[:, i]
        
        # ç”»æ•£ç‚¹å›¾
        plt.scatter(y_t, y_p, alpha=0.6, s=20)
        
        # ç”»ç†æƒ³çº¿
        min_val = min(y_t.min(), y_p.min())
        max_val = max(y_t.max(), y_p.max())
        plt.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=1)
        
        # è®¡ç®— RÂ²
        r2 = r2_score(y_t, y_p)
        
        plt.xlabel('True Value')
        plt.ylabel('Predicted Value')
        plt.title(f'{name} (RÂ²={r2:.4f})')
        plt.grid(True, alpha=0.3)
    
    plt.suptitle(f'{model_name} - Predictions vs True Values', fontsize=16)
    plt.tight_layout()
    
    if save_path:
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"âœ… é¢„æµ‹å›¾å·²ä¿å­˜: {save_path}")
    
    plt.show()

def save_results_to_csv(metrics, model_name, output_path="experiments/results/comparison.csv"):
    """
    å°†ç»“æœä¿å­˜åˆ° CSV æ–‡ä»¶ä¸­
    
    Parameters:
    - metrics: è¯„ä¼°æŒ‡æ ‡å­—å…¸
    - model_name: æ¨¡å‹åç§°
    - output_path: è¾“å‡ºè·¯å¾„
    """
    # å‡†å¤‡æ•°æ®
    row_data = {'Model': model_name}
    
    for target, scores in metrics.items():
        if target != 'Average':
            row_data[f'{target}_R2'] = scores['R2']
            row_data[f'{target}_RMSE'] = scores['RMSE']
            row_data[f'{target}_MAE'] = scores['MAE']
    
    # æ·»åŠ å¹³å‡å€¼
    row_data['Avg_R2'] = metrics['Average']['R2']
    row_data['Avg_RMSE'] = metrics['Average']['RMSE']
    
    # åˆ›å»º DataFrame
    df_new = pd.DataFrame([row_data])
    
    # å¦‚æœæ–‡ä»¶å­˜åœ¨ï¼Œè¿½åŠ ï¼›å¦åˆ™åˆ›å»ºæ–°æ–‡ä»¶
    if os.path.exists(output_path):
        df_existing = pd.read_csv(output_path)
        df_combined = pd.concat([df_existing, df_new], ignore_index=True)
    else:
        df_combined = df_new
    
    # ä¿å­˜
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    df_combined.to_csv(output_path, index=False)
    print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {output_path}")

def load_data(csv_path="/ssd1/zhanghongbo04/002/project/NIR-Corn/data/combined_dataset.csv", test_size=0.2, random_state=42):
    """
    åŠ è½½å¹¶é¢„å¤„ç†æ•°æ®
    
    Returns:
    - X_train, X_test, y_train, y_test: åˆ’åˆ†åçš„æ•°æ®
    - scaler_X, scaler_y: å½’ä¸€åŒ–å™¨
    """
    from sklearn.preprocessing import StandardScaler
    from sklearn.model_selection import train_test_split
    
    print(f"ğŸ“Š åŠ è½½æ•°æ®: {csv_path}")
    df = pd.read_csv(csv_path)
    
    # æå–ç‰¹å¾å’Œæ ‡ç­¾
    X = df.iloc[:, 1:701].values  # Wave_1 ~ Wave_700
    y = df.iloc[:, 701:].values   # Moisture, Starch, Oil, Protein
    
    print(f"âœ… æ•°æ®å½¢çŠ¶: X={X.shape}, y={y.shape}")
    
    # åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›†
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state
    )
    
    # æ ‡å‡†åŒ–
    scaler_X = StandardScaler()
    scaler_y = StandardScaler()
    
    X_train_scaled = scaler_X.fit_transform(X_train)
    X_test_scaled = scaler_X.transform(X_test)
    y_train_scaled = scaler_y.fit_transform(y_train)
    y_test_scaled = scaler_y.transform(y_test)
    
    print(f"ğŸ“Š è®­ç»ƒé›†: {X_train_scaled.shape}, æµ‹è¯•é›†: {X_test_scaled.shape}")
    
    return (X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, 
            scaler_X, scaler_y, y_train, y_test)

if __name__ == "__main__":
    print("âœ… utils.py å·²åŠ è½½")
    print("å¯ç”¨å‡½æ•°:")
    print("  - evaluate_model()")
    print("  - plot_predictions()")
    print("  - save_results_to_csv()")
    print("  - load_data()")