# experiments/xgboost_experiment.py

import numpy as np
from xgboost import XGBRegressor
from sklearn.multioutput import MultiOutputRegressor
import joblib
import os
import time

# å¯¼å…¥å·¥å…·å‡½æ•°
from utils import load_data, evaluate_model, plot_predictions, save_results_to_csv

def run_xgboost_experiment():
    """è¿è¡Œ XGBoost å®éªŒ"""
    print("ğŸš€ å¼€å§‹ XGBoost å®éªŒ...")
    
    # åŠ è½½æ•°æ®
    (X_train, X_test, y_train_scaled, y_test_scaled, 
     scaler_X, scaler_y, y_train_orig, y_test_orig) = load_data()
    
    # ä¸ºäº†åŠ å¿«è®­ç»ƒé€Ÿåº¦ï¼Œä½¿ç”¨éƒ¨åˆ†æ•°æ®è¿›è¡Œè®­ç»ƒ
    print("ğŸ” è®­ç»ƒ XGBoost æ¨¡å‹...")
    
    # ä½¿ç”¨æ›´å°‘çš„ estimators å’Œæ›´ç®€å•çš„å‚æ•°
    xgb_params = {
        'random_state': 42,
        'n_estimators': 50,      # å‡å°‘æ ‘çš„æ•°é‡
        'max_depth': 4,          # å‡å°‘æ·±åº¦
        'learning_rate': 0.1,
        'subsample': 0.8,        # éšæœºé‡‡æ ·
        'colsample_bytree': 0.8, # ç‰¹å¾é‡‡æ ·
        'n_jobs': -1             # ä½¿ç”¨æ‰€æœ‰ CPU æ ¸å¿ƒ
    }
    
    # åˆ›å»ºå¤šè¾“å‡ºå›å½’å™¨
    multi_xgb = MultiOutputRegressor(
        XGBRegressor(**xgb_params),
        n_jobs=1  # é¿å…åµŒå¥—å¹¶è¡Œ
    )
    
    # è®­ç»ƒæ¨¡å‹ï¼ˆæ·»åŠ è¿›åº¦æç¤ºï¼‰
    print("â³ æ­£åœ¨è®­ç»ƒæ¨¡å‹ï¼Œè¯·ç¨å€™...")
    start_time = time.time()
    
    try:
        multi_xgb.fit(X_train, y_train_scaled)
        train_time = time.time() - start_time
        print(f"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {train_time:.2f} ç§’")
    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        # å°è¯•æ›´ç®€å•çš„å‚æ•°
        print("ğŸ”„ å°è¯•æ›´ç®€å•çš„å‚æ•°...")
        simple_params = {
            'random_state': 42,
            'n_estimators': 30,
            'max_depth': 3,
            'learning_rate': 0.1,
            'n_jobs': -1
        }
        multi_xgb = MultiOutputRegressor(XGBRegressor(**simple_params), n_jobs=1)
        multi_xgb.fit(X_train, y_train_scaled)
        print("âœ… ä½¿ç”¨ç®€åŒ–å‚æ•°è®­ç»ƒå®Œæˆ")
    
    # é¢„æµ‹
    print("ğŸ”® è¿›è¡Œé¢„æµ‹...")
    y_pred_scaled = multi_xgb.predict(X_test)
    y_pred_orig = scaler_y.inverse_transform(y_pred_scaled)
    
    # è¯„ä¼°
    metrics = evaluate_model(
        y_test_orig, y_pred_orig, 
        model_name="XGBoost",
        scaler_y=None
    )
    
    # ç”»å›¾
    plot_predictions(
        y_test_orig, y_pred_orig,
        model_name="XGBoost",
        save_path="experiments/results/xgboost_predictions.png"
    )
    
    # ä¿å­˜ç»“æœåˆ° CSV
    save_results_to_csv(metrics, "XGBoost")
    
    # ä¿å­˜æ¨¡å‹å’Œå½’ä¸€åŒ–å™¨
    model_dir = "experiments/models"
    os.makedirs(model_dir, exist_ok=True)
    
    joblib.dump(multi_xgb, os.path.join(model_dir, "xgboost_model.pkl"))
    joblib.dump(scaler_X, os.path.join(model_dir, "xgboost_scaler_X.pkl"))
    joblib.dump(scaler_y, os.path.join(model_dir, "xgboost_scaler_y.pkl"))
    
    print("âœ… XGBoost å®éªŒå®Œæˆ")
    print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜åˆ°: {model_dir}")
    
    return metrics

if __name__ == "__main__":
    run_xgboost_experiment()