# scripts/create_combined_dataset.py

import numpy as np
import pandas as pd
import os

def load_processed_data(data_dir="data/processed_interpolated"):
    """åŠ è½½å¤„ç†åçš„æ•°æ®"""
    print(f"ğŸ”„ åŠ è½½å¤„ç†åçš„æ•°æ®ä»: {data_dir}")
    
    # åŠ è½½åŸå§‹æ•°æ®ï¼ˆæœªå½’ä¸€åŒ–ï¼‰
    X_real = np.load(os.path.join(data_dir, "X_real_original.npy"))      # (80, 700)
    y_real = np.load(os.path.join(data_dir, "y_real_original.npy"))      # (80, 4)
    
    # åŠ è½½æ’å€¼æ•°æ®ï¼ˆæœªå½’ä¸€åŒ–ï¼‰
    X_fake = np.load(os.path.join(data_dir, "X_interpolated_original.npy"))  # (920, 700)
    y_fake = np.load(os.path.join(data_dir, "y_interpolated_original.npy"))  # (920, 4)
    
    print(f"âœ… åŸå§‹æ•°æ®: å…‰è°± {X_real.shape}, æ ‡ç­¾ {y_real.shape}")
    print(f"âœ… æ’å€¼æ•°æ®: å…‰è°± {X_fake.shape}, æ ‡ç­¾ {y_fake.shape}")
    
    return X_real, y_real, X_fake, y_fake

def create_combined_csv(X_real, y_real, X_fake, y_fake, output_path="data/combined_dataset.csv"):
    """åˆ›å»ºåˆå¹¶çš„ CSV æ–‡ä»¶"""
    print("ğŸ”„ åˆ›å»ºåˆå¹¶çš„ CSV æ–‡ä»¶...")
    
    # åˆå¹¶æ•°æ®
    X_combined = np.vstack([X_real, X_fake])  # (1000, 700)
    y_combined = np.vstack([y_real, y_fake])  # (1000, 4)
    
    print(f"ğŸ“Š åˆå¹¶åæ•°æ®å½¢çŠ¶: å…‰è°± {X_combined.shape}, æ ‡ç­¾ {y_combined.shape}")
    
    # åˆ›å»ºæ³¢é•¿åˆ—å
    wavelength_cols = [f'Wave_{i+1}' for i in range(X_combined.shape[1])]
    
    # åˆ›å»º DataFrame
    df_spectra = pd.DataFrame(X_combined, columns=wavelength_cols)
    
    # æ·»åŠ æ ·æœ¬ ID
    sample_ids = [f"S{i+1:04d}" for i in range(X_combined.shape[0])]
    df_spectra.insert(0, 'SampleID', sample_ids)
    
    # æ·»åŠ æ ‡ç­¾
    target_names = ['Moisture', 'Starch', 'Oil', 'Protein']
    df_labels = pd.DataFrame(y_combined, columns=target_names)
    
    # åˆå¹¶æ‰€æœ‰åˆ—
    df_combined = pd.concat([df_spectra, df_labels], axis=1)
    
    # ä¿å­˜ä¸º CSV
    df_combined.to_csv(output_path, index=False)
    print(f"âœ… åˆå¹¶ CSV å·²ä¿å­˜: {output_path}")
    print(f"ğŸ“ æ–‡ä»¶å¤§å°: {df_combined.shape}")
    
    # æ˜¾ç¤ºå‰å‡ è¡Œé¢„è§ˆ
    print("\nğŸ“‹ æ•°æ®é¢„è§ˆ:")
    print(df_combined.head(3).to_string())
    
    return df_combined

def create_dataset_info(df_combined, output_dir="data"):
    """åˆ›å»ºæ•°æ®é›†ä¿¡æ¯æ–‡ä»¶"""
    info = {
        "total_samples": len(df_combined),
        "spectral_dimensions": 700,
        "target_variables": ['Moisture', 'Starch', 'Oil', 'Protein'],
        "data_source": "Real + Interpolated samples",
        "real_samples": 80,
        "interpolated_samples": 1920
    }
    
    info_path = os.path.join(output_dir, "dataset_info.txt")
    with open(info_path, 'w') as f:
        for key, value in info.items():
            f.write(f"{key}: {value}\n")
    
    print(f"ğŸ“ æ•°æ®é›†ä¿¡æ¯å·²ä¿å­˜: {info_path}")
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print("\nğŸ“ˆ æ•°æ®é›†ç»Ÿè®¡:")
    for target in ['Moisture', 'Starch', 'Oil', 'Protein']:
        values = df_combined[target]
        print(f"  {target}: min={values.min():.3f}, max={values.max():.3f}, mean={values.mean():.3f}")

def main():
    # åŠ è½½æ•°æ®
    X_real, y_real, X_fake, y_fake = load_processed_data()
    
    # åˆ›å»ºåˆå¹¶çš„ CSV
    df_combined = create_combined_csv(X_real, y_real, X_fake, y_fake)
    
    # åˆ›å»ºæ•°æ®é›†ä¿¡æ¯
    create_dataset_info(df_combined)
    
    print("\nğŸ‰ åˆå¹¶æ•°æ®é›†åˆ›å»ºå®Œæˆï¼")
    print("ğŸ“ è¾“å‡ºæ–‡ä»¶:")
    print("  - data/combined_dataset.csv")
    print("  - data/dataset_info.txt")

if __name__ == "__main__":
    main()